{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import os\n",
    "import xgboost_util_py3 as xgboost_util\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "NUMBER_OF_TREES = 50\n",
    "WINDOW_SIZE = 5\n",
    "\n",
    "#TEST_NAME = 'PageRank'\n",
    "#TEST_NAME = 'KMeans'\n",
    "TEST_NAME = 'SGD'\n",
    "#TEST_NAME = 'tensorflow'\n",
    "#TEST_NAME = 'web_server'\n",
    "\n",
    "TARGET_COLUMN = 'flow_size'\n",
    "\n",
    "TRAINING_PATH = '../data/ml/' + TEST_NAME + '/training/'\n",
    "TEST_PATH = '../data/ml/' + TEST_NAME + '/test/'\n",
    "VALIDATION_PATH = '../data/ml/' + TEST_NAME + '/validation/'\n",
    "\n",
    "training_files = [os.path.join(TRAINING_PATH, f) for f in os.listdir(TRAINING_PATH)]\n",
    "test_files = [os.path.join(TEST_PATH, f) for f in os.listdir(TEST_PATH)]\n",
    "validation_files = [os.path.join(VALIDATION_PATH, f) for f in os.listdir(VALIDATION_PATH)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scaling(training_paths):\n",
    "    scaling = {}\n",
    "    #calculate scaling factors\n",
    "    for f in training_paths:\n",
    "        df = pd.read_csv(f, index_col=False)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column not in scaling:\n",
    "               scaling[column] = 0.\n",
    "            scaling[column] = max(scaling[column], float(df[column].max().split()[-1]))\n",
    "    return scaling\n",
    "\n",
    "\n",
    "def prepare_files(files, window_size, scaling, target_column='flow_size'):\n",
    "    result = []\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, index_col=False)\n",
    "\n",
    "        print(df)\n",
    "        df = df.drop(\"index\", axis=1)\n",
    "        \n",
    "\n",
    "        df = df.apply((lambda x: resize(x, scaling)), axis=0)\n",
    "        flow_size = df[target_column]\n",
    "        df[target_column] = flow_size\n",
    "        #extend the window\n",
    "        columns = list(df)\n",
    "        final_df = df.copy()\n",
    "        for sample_num in range(1, window_size):\n",
    "            shifted = df.shift(sample_num)\n",
    "            shifted.columns = map(lambda x: x+str(sample_num), shifted.columns)\n",
    "            final_df = concat([shifted, final_df], axis=1)\n",
    "\n",
    "        final_df = final_df.fillna(0)\n",
    "        final_df = final_df.drop(target_column, axis=1)\n",
    "\n",
    "        result.append((final_df, flow_size))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "scaling = calculate_scaling(training_files)\n",
    "#prepare_files(training_files, WINDOW_SIZE, scaling, TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b9aaca0b08e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fit model no training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/minors/flux/ml/xgboost_util_py3.py\u001b[0m in \u001b[0;36mmake_io\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "#scaling = xgboost_util.calculate_scaling(training_files)\n",
    "#data = xgboost_util.prepare_files(training_files, WINDOW_SIZE, scaling, TARGET_COLUMN)\n",
    "data = scaling\n",
    "\n",
    "inputs, outputs = xgboost_util.make_io(data)\n",
    "\n",
    "# fit model no training data\n",
    "param = {\n",
    "    'num_epochs' : NUMBER_OF_TREES,\n",
    "    'max_depth' : 10,\n",
    "    'objective' : 'reg:linear',\n",
    "    'booster' : 'gbtree',\n",
    "    'base_score' : 2,\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mae'\n",
    "}\n",
    "\n",
    "training = xgboost.DMatrix(inputs, outputs, feature_names = data[0][0].columns)\n",
    "print(len(outputs))\n",
    "print('Training started')\n",
    "model = xgboost.train(param, training, param['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance(files, write_to_simulator=False):\n",
    "    real = []\n",
    "    predicted = []\n",
    "    for f in files:\n",
    "        data = xgboost_util.prepare_files([f], WINDOW_SIZE, scaling, TARGET_COLUMN)\n",
    "        inputs, outputs = xgboost_util.make_io(data)\n",
    "\n",
    "        y_pred = model.predict(xgboost.DMatrix(inputs, feature_names = data[0][0].columns))\n",
    "        pred = y_pred.tolist()\n",
    "\n",
    "        real += outputs\n",
    "        predicted += pred\n",
    "\n",
    "    xgboost_util.print_metrics(real, predicted)\n",
    "\n",
    "print 'TRAINING'\n",
    "print_performance(training_files)\n",
    "print\n",
    "\n",
    "print 'TEST'\n",
    "print_performance(test_files)\n",
    "print\n",
    "\n",
    "print 'VALIDATION'\n",
    "print_performance(validation_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
